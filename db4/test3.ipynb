{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la ruta de la base de datos\n",
    "database_path = '../../database/105_classes_pins_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos con ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)  # Especificar el split de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generadores de datos para entrenamiento y validación\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    database_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training')  # Indicar que es el subset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3463 images belonging to 105 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    database_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')  # Indicar que es el subset de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar capas convolucionales y de pooling\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar capas fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))  # Número de clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          epochs=10,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Definir la ruta de la base de datos\n",
    "database_path = '../../database/105_classes_pins_dataset/'\n",
    "\n",
    "# Preprocesamiento de datos con ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)  # Especificar el split de entrenamiento y validación\n",
    "\n",
    "# Generadores de datos para entrenamiento y validación\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    database_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training')  # Indicar que es el subset de entrenamiento\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    database_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')  # Indicar que es el subset de validación\n",
    "\n",
    "num_classes = len(train_generator.class_indices)  # Obtener el número de clases\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "# Añadir más capas o ajustar el modelo según sea necesario\n",
    "\n",
    "# Capa de salida con el número correcto de clases y activación softmax\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo usando la GPU si está disponible\n",
    "with tf.device('/GPU:1'):\n",
    "    model.fit(train_generator,\n",
    "              steps_per_epoch=len(train_generator),\n",
    "              epochs=10,\n",
    "              validation_data=validation_generator,\n",
    "              validation_steps=len(validation_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se ha detectado una GPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verificar si hay GPU disponible\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(f\"Detalles de la GPU utilizada:\\n{gpu}\")\n",
    "        print(\"Memoria disponible:\", tf.config.experimental.get_memory_info(gpu))\n",
    "else:\n",
    "    print(\"No se ha detectado una GPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17534 images belonging to 105 classes.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'ruta/datos_validacion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Familia\\Desktop\\Red Black Tree\\Proyecto\\project4-machine\\db4\\test3.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m validation_datagen \u001b[39m=\u001b[39m ImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m train_generator \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m../../database/105_classes_pins_dataset/\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m validation_generator \u001b[39m=\u001b[39m validation_datagen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mruta/datos_validacion\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     target_size\u001b[39m=\u001b[39;49m(\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Obtener imágenes y etiquetas\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Familia/Desktop/Red%20Black%20Tree/Proyecto/project4-machine/db4/test3.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m X_train, y_train \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(train_generator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:1649\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[39m        and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1649\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1650\u001b[0m         directory,\n\u001b[0;32m   1651\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1652\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1653\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1654\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m   1655\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1656\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1657\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1658\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1659\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1660\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1661\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1662\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1663\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1664\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m   1665\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1666\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1667\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1668\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'ruta/datos_validacion'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Preprocesamiento de datos con ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../../database/105_classes_pins_dataset/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '../../database/105_classes_pins_dataset/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Obtener imágenes y etiquetas\n",
    "X_train, y_train = next(train_generator)\n",
    "X_val, y_val = next(validation_generator)\n",
    "\n",
    "# Aplanar las imágenes para PCA\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flatten = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "# Normalizar los datos (opcional)\n",
    "X_train_flatten = X_train_flatten / 255.0\n",
    "X_val_flatten = X_val_flatten / 255.0\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=100)  # Número de componentes deseados\n",
    "pca.fit(X_train_flatten)\n",
    "\n",
    "# Transformar los datos de entrenamiento y validación con PCA\n",
    "X_train_pca = pca.transform(X_train_flatten)\n",
    "X_val_pca = pca.transform(X_val_flatten)\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(100,)),  # 100 es el número de componentes de PCA\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes es el número de clases de actores que tienes\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo con las características transformadas por PCA\n",
    "model.fit(X_train_pca, y_train, epochs=10, validation_data=(X_val_pca, y_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
